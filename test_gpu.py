# test_gpu.py

import torch

def test_gpu():
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        device_count = torch.cuda.device_count()
        print(f"âœ… GPU å¯ç”¨ï¼Œå…± {device_count} å— GPU")
        print(f"ğŸ–¥ï¸ å½“å‰ä½¿ç”¨çš„ GPU: {device_name}")
        print("ğŸš€ æµ‹è¯•å¼ é‡è®¡ç®—ä¸­...")

        # æµ‹è¯•å¼ é‡è¿ç®—æ˜¯å¦æ­£å¸¸
        x = torch.randn(10000, 10000).cuda()
        y = torch.matmul(x, x)
        print("ğŸ‰ å¼ é‡è®¡ç®—æˆåŠŸï¼Œç»“æœå½¢çŠ¶ï¼š", y.shape)
    else:
        print("âŒ å½“å‰ç¯å¢ƒä¸­ GPU ä¸å¯ç”¨")

if __name__ == "__main__":
    test_gpu()
    
    import torch
    print(torch.version.cuda)
    print(torch.backends.cudnn.version())
    print(torch.cuda.get_device_name(0))